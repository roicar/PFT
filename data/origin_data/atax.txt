pluto_tile_parallel:
0.0012738070

default tvm:
Execution time of this operator: max:0.0022067120 s   median:0.0021799878 s   min:0.0021658241 s


default ansor:
Execution time of this operator: max:0.0000657981 s   median:0.0000572439 s   min:0.0000498109 s
Equivalent python schedule:
compute_i, compute_k = tuple(compute.op.axis) + tuple(compute.op.reduce_axis)
compute_i, compute_t = tuple(compute.op.axis) + tuple(compute.op.reduce_axis)
compute_i_o_i, compute_i_i = s[compute].split(compute_i, factor=8)
compute_i_o_o_i, compute_i_o_i = s[compute].split(compute_i_o_i, factor=2)
compute_i_o_o_o, compute_i_o_o_i = s[compute].split(compute_i_o_o_i, factor=64)
compute_t_o, compute_t_i = s[compute].split(compute_t, factor=16)
s[compute].reorder(compute_i_o_o_o, compute_i_o_o_i, compute_t_o, compute_i_o_i, compute_t_i, compute_i_i)
compute_local, = s.cache_write([compute], "local")
compute_local_i_c, compute_local_k = tuple(compute_local.op.axis) + tuple(compute_local.op.reduce_axis)
compute_local_i_c_o_i, compute_local_i_c_i = s[compute_local].split(compute_local_i_c, factor=2)
compute_local_i_c_o_o_i, compute_local_i_c_o_i = s[compute_local].split(compute_local_i_c_o_i, factor=2)
compute_local_i_c_o_o_o, compute_local_i_c_o_o_i = s[compute_local].split(compute_local_i_c_o_o_i, factor=1)
compute_local_k_o, compute_local_k_i = s[compute_local].split(compute_local_k, factor=2)
s[compute_local].reorder(compute_local_i_c_o_o_o, compute_local_i_c_o_o_i, compute_local_k_o, compute_local_i_c_o_i, compute_local_k_i, compute_local_i_c_i)
compute_i_o, compute_i_i = s[compute].split(compute_i, factor=4)
s[compute].reorder(compute_i_o, compute_i_i)
s[compute_local].compute_at(s[compute], compute_i_o)
s[compute].parallel(compute_i_o)
compute_i_o_o_o_i_o_o_i_fused = s[compute].fuse(compute_i_o_o_o, compute_i_o_o_i)
s[compute].parallel(compute_i_o_o_o_i_o_o_i_fused)
s[compute_local].pragma(compute_local_i_c_o_o_o, "auto_unroll_max_step", 64)
s[compute_local].pragma(compute_local_i_c_o_o_o, "unroll_explicit", True)
s[compute].pragma(compute_i_o_o_o_i_o_o_i_fused, "auto_unroll_max_step", 16)
s[compute].pragma(compute_i_o_o_o_i_o_o_i_fused, "unroll_explicit", True)
s[compute_local].vectorize(compute_local_i_c_i)
s[compute].vectorize(compute_i_i)
s[compute].vectorize(compute_i_i)


ppcg cuda:
0.0000798720




gpu ansor:Execution time of this operator: max:0.0000308079 s   median:0.0000307752 s   min:0.0000307211 s
Equivalent python schedule:
compute_i, compute_k = tuple(compute.op.axis) + tuple(compute.op.reduce_axis)
compute_i, compute_t = tuple(compute.op.axis) + tuple(compute.op.reduce_axis)
compute_local, = s.cache_write([compute], "local")
compute_local_i_c, compute_local_t = tuple(compute_local.op.axis) + tuple(compute_local.op.reduce_axis)
compute_local_i_c_o_i, compute_local_i_c_i = s[compute_local].split(compute_local_i_c, factor=1)
compute_local_i_c_o_o_i, compute_local_i_c_o_i = s[compute_local].split(compute_local_i_c_o_i, factor=1)
compute_local_i_c_o_o_o_i, compute_local_i_c_o_o_i = s[compute_local].split(compute_local_i_c_o_o_i, factor=32)
compute_local_i_c_o_o_o_o, compute_local_i_c_o_o_o_i = s[compute_local].split(compute_local_i_c_o_o_o_i, factor=1)
compute_local_t_o_i, compute_local_t_i = s[compute_local].split(compute_local_t, factor=32)
compute_local_t_o_o, compute_local_t_o_i = s[compute_local].split(compute_local_t_o_i, factor=2)
s[compute_local].reorder(compute_local_i_c_o_o_o_o, compute_local_i_c_o_o_o_i, compute_local_i_c_o_o_i, compute_local_t_o_o, compute_local_t_o_i, compute_local_i_c_o_i, compute_local_t_i, compute_local_i_c_i)
compute_i_o_i, compute_i_i = s[compute].split(compute_i, factor=1)
compute_i_o_o_i, compute_i_o_i = s[compute].split(compute_i_o_i, factor=32)
compute_i_o_o_o, compute_i_o_o_i = s[compute].split(compute_i_o_o_i, factor=1)
s[compute].reorder(compute_i_o_o_o, compute_i_o_o_i, compute_i_o_i, compute_i_i)
s[compute_local].compute_at(s[compute], compute_i_o_i)
compute_shared = s.cache_read(compute, "shared", [compute_local])
compute_shared_ax0 = tuple(compute_shared.op.axis)
s[compute_shared].compute_at(s[compute_local], compute_local_t_o_o)
compute_local, = s.cache_write([compute], "local")
compute_local_i_c, compute_local_k = tuple(compute_local.op.axis) + tuple(compute_local.op.reduce_axis)
compute_local_i_c_o_i, compute_local_i_c_i = s[compute_local].split(compute_local_i_c, factor=1)
compute_local_i_c_o_o_i, compute_local_i_c_o_i = s[compute_local].split(compute_local_i_c_o_i, factor=1)
compute_local_i_c_o_o_o_i, compute_local_i_c_o_o_i = s[compute_local].split(compute_local_i_c_o_o_i, factor=16)
compute_local_i_c_o_o_o_o, compute_local_i_c_o_o_o_i = s[compute_local].split(compute_local_i_c_o_o_o_i, factor=1)
compute_local_k_o_i, compute_local_k_i = s[compute_local].split(compute_local_k, factor=32)
compute_local_k_o_o, compute_local_k_o_i = s[compute_local].split(compute_local_k_o_i, factor=2)
s[compute_local].reorder(compute_local_i_c_o_o_o_o, compute_local_i_c_o_o_o_i, compute_local_i_c_o_o_i, compute_local_k_o_o, compute_local_k_o_i, compute_local_i_c_o_i, compute_local_k_i, compute_local_i_c_i)
compute_i_o_i, compute_i_i = s[compute].split(compute_i, factor=1)
compute_i_o_o_i, compute_i_o_i = s[compute].split(compute_i_o_i, factor=16)
compute_i_o_o_o, compute_i_o_o_i = s[compute].split(compute_i_o_o_i, factor=1)
s[compute].reorder(compute_i_o_o_o, compute_i_o_o_i, compute_i_o_i, compute_i_i)
s[compute_local].compute_at(s[compute], compute_i_o_i)
x_shared = s.cache_read(x, "shared", [compute_local])
x_shared_ax0 = tuple(x_shared.op.axis)
s[x_shared].compute_at(s[compute_local], compute_local_k_o_o)
A_shared = s.cache_read(A, "shared", [compute_local])
A_shared_ax0, A_shared_ax1 = tuple(A_shared.op.axis)
s[A_shared].compute_at(s[compute_local], compute_local_k_o_o)
A_d_shared = s.cache_read(A, "shared", [compute_local])
A_d_shared_ax0, A_d_shared_ax1 = tuple(A_d_shared.op.axis)
s[A_d_shared].compute_at(s[compute_local], compute_local_t_o_o)
compute_i_o_o_o = s[compute].fuse(compute_i_o_o_o)
s[compute].bind(compute_i_o_o_o, te.thread_axis("blockIdx.x"))
compute_i_o_o_i = s[compute].fuse(compute_i_o_o_i)
s[compute].bind(compute_i_o_o_i, te.thread_axis("vthread"))
compute_i_o_i = s[compute].fuse(compute_i_o_i)
s[compute].bind(compute_i_o_i, te.thread_axis("threadIdx.x"))
compute_shared_ax0 = s[compute_shared].fuse(compute_shared_ax0)
compute_shared_ax0_o, compute_shared_ax0_i = s[compute_shared].split(compute_shared_ax0, factor=2)
s[compute_shared].vectorize(compute_shared_ax0_i)
compute_shared_ax0_o_o, compute_shared_ax0_o_i = s[compute_shared].split(compute_shared_ax0_o, factor=32)
s[compute_shared].bind(compute_shared_ax0_o_i, te.thread_axis("threadIdx.x"))
compute_i_o_o_o = s[compute].fuse(compute_i_o_o_o)
s[compute].bind(compute_i_o_o_o, te.thread_axis("blockIdx.x"))
compute_i_o_o_i = s[compute].fuse(compute_i_o_o_i)
s[compute].bind(compute_i_o_o_i, te.thread_axis("vthread"))
compute_i_o_i = s[compute].fuse(compute_i_o_i)
s[compute].bind(compute_i_o_i, te.thread_axis("threadIdx.x"))
x_shared_ax0 = s[x_shared].fuse(x_shared_ax0)
x_shared_ax0_o, x_shared_ax0_i = s[x_shared].split(x_shared_ax0, factor=4)
s[x_shared].vectorize(x_shared_ax0_i)
x_shared_ax0_o_o, x_shared_ax0_o_i = s[x_shared].split(x_shared_ax0_o, factor=16)
s[x_shared].bind(x_shared_ax0_o_i, te.thread_axis("threadIdx.x"))
A_shared_ax0_ax1_fused = s[A_shared].fuse(A_shared_ax0, A_shared_ax1)
A_shared_ax0_ax1_fused_o, A_shared_ax0_ax1_fused_i = s[A_shared].split(A_shared_ax0_ax1_fused, factor=4)
s[A_shared].vectorize(A_shared_ax0_ax1_fused_i)
A_shared_ax0_ax1_fused_o_o, A_shared_ax0_ax1_fused_o_i = s[A_shared].split(A_shared_ax0_ax1_fused_o, factor=16)
s[A_shared].bind(A_shared_ax0_ax1_fused_o_i, te.thread_axis("threadIdx.x"))
A_d_shared_ax0_ax1_fused = s[A_d_shared].fuse(A_d_shared_ax0, A_d_shared_ax1)
A_d_shared_ax0_ax1_fused_o, A_d_shared_ax0_ax1_fused_i = s[A_d_shared].split(A_d_shared_ax0_ax1_fused, factor=4)
s[A_d_shared].vectorize(A_d_shared_ax0_ax1_fused_i)
A_d_shared_ax0_ax1_fused_o_o, A_d_shared_ax0_ax1_fused_o_i = s[A_d_shared].split(A_d_shared_ax0_ax1_fused_o, factor=32)
s[A_d_shared].bind(A_d_shared_ax0_ax1_fused_o_i, te.thread_axis("threadIdx.x"))
s[compute_local].pragma(compute_local_i_c_o_o_o_o, "auto_unroll_max_step", 1024)
s[compute_local].pragma(compute_local_i_c_o_o_o_o, "unroll_explicit", True)
s[compute_local].pragma(compute_local_i_c_o_o_o_o, "auto_unroll_max_step", 0)
s[compute_local].pragma(compute_local_i_c_o_o_o_o, "unroll_explicit", True)